{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHICN2lEOHxw",
        "outputId": "b7f70553-52e3-4464-ca35-c0442cdb03b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "cfg_path = Path(\"/content/drive/MyDrive/UrbanSimAI_Chicago/urbansim_config.json\")\n",
        "cfg = json.loads(cfg_path.read_text())\n",
        "\n",
        "PROJECT_ROOT = Path(cfg[\"PROJECT_ROOT\"])\n",
        "RAW_DIR = Path(cfg[\"RAW_DIR\"])\n",
        "PROC_DIR = Path(cfg[\"PROC_DIR\"])\n",
        "REPORT_DIR = Path(cfg[\"REPORT_DIR\"])\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "\n",
        "DEPLOY_DIR = PROJECT_ROOT / \"deploy_streamlit_repo\"\n",
        "DATA_DIR = DEPLOY_DIR / \"data\"\n",
        "MODEL_OUT = DEPLOY_DIR / \"models\"\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"✅ PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"✅ PROC_DIR:\", PROC_DIR)\n",
        "print(\"✅ MODELS_DIR:\", MODELS_DIR)\n",
        "print(\"✅ DEPLOY_DIR:\", DEPLOY_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCifM0LaORdR",
        "outputId": "53c846d0-f502-48bb-945f-518f07b236f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PROJECT_ROOT: /content/drive/MyDrive/UrbanSimAI_Chicago\n",
            "✅ PROC_DIR: /content/drive/MyDrive/UrbanSimAI_Chicago/data_processed\n",
            "✅ MODELS_DIR: /content/drive/MyDrive/UrbanSimAI_Chicago/models\n",
            "✅ DEPLOY_DIR: /content/drive/MyDrive/UrbanSimAI_Chicago/deploy_streamlit_repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas numpy pyarrow fastparquet joblib holidays geopandas shapely"
      ],
      "metadata": {
        "id": "3-xdTB9bOriT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src_model = MODELS_DIR / \"best_speed_model.pkl\"\n",
        "src_meta  = MODELS_DIR / \"best_speed_model_meta.json\"\n",
        "\n",
        "assert src_model.exists(), f\"Missing: {src_model}\"\n",
        "assert src_meta.exists(),  f\"Missing: {src_meta}\"\n",
        "\n",
        "shutil.copy2(src_model, MODEL_OUT / src_model.name)\n",
        "shutil.copy2(src_meta,  MODEL_OUT / src_meta.name)\n",
        "\n",
        "print(\"✅ Copied model:\", src_model.name)\n",
        "print(\"✅ Copied meta :\", src_meta.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuHGy4NfRkKI",
        "outputId": "c08d73e2-d3ea-4e9a-a34d-1c7c085bb2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Copied model: best_speed_model.pkl\n",
            "✅ Copied meta : best_speed_model_meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_to_copy = [\n",
        "    \"traffic_zip_hourly.parquet\",\n",
        "    \"cta_stops_by_zip.parquet\",\n",
        "    \"zillow_zhvi_chicago_zip_long.parquet\",\n",
        "]\n",
        "\n",
        "for fn in files_to_copy:\n",
        "    src = PROC_DIR / fn\n",
        "    assert src.exists(), f\"Missing processed file: {src}\"\n",
        "    shutil.copy2(src, DATA_DIR / fn)\n",
        "    print(\"✅ Copied:\", fn)\n",
        "\n",
        "print(\"✅ All processed data copied.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTO01s1fTeGI",
        "outputId": "1c1cd1b1-f84e-4137-a540-623273c9c310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Copied: traffic_zip_hourly.parquet\n",
            "✅ Copied: cta_stops_by_zip.parquet\n",
            "✅ Copied: zillow_zhvi_chicago_zip_long.parquet\n",
            "✅ All processed data copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "zip_parquet = PROC_DIR / \"zip_boundaries.parquet\"\n",
        "assert zip_parquet.exists(), f\"Missing: {zip_parquet}\"\n",
        "\n",
        "zip_geojson = DATA_DIR / \"zip_boundaries.geojson\"\n",
        "\n",
        "gdf = gpd.read_parquet(zip_parquet)\n",
        "gdf[\"zip\"] = gdf[\"zip\"].astype(str).str.zfill(5)\n",
        "\n",
        "gdf.to_file(zip_geojson, driver=\"GeoJSON\")\n",
        "print(\"✅ Created:\", zip_geojson, \"| MB:\", round(zip_geojson.stat().st_size/1e6, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-hZS3b2Tu2g",
        "outputId": "1a3ecd9e-eeef-42d4-9b37-2ab80746eb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created: /content/drive/MyDrive/UrbanSimAI_Chicago/deploy_streamlit_repo/data/zip_boundaries.geojson | MB: 1.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "numpy\n",
        "pyarrow\n",
        "fastparquet\n",
        "joblib\n",
        "holidays\n",
        "xgboost\n",
        "pydeck\n",
        "\"\"\"\n",
        "(DEPLOY_DIR / \"requirements.txt\").write_text(requirements)\n",
        "print(\"✅ requirements.txt saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu6IFRxTPqU4",
        "outputId": "9aa12ef0-05f3-4115-8a77-b8c3f3d14359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ requirements.txt saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gitignore = \"\"\"# ignore raw / large stuff\n",
        "data_raw/\n",
        "**/*.csv\n",
        "**/*.csv.part\n",
        "**/*parts*\n",
        "*.ipynb_checkpoints\n",
        ".DS_Store\n",
        "__pycache__/\n",
        "\"\"\"\n",
        "(DEPLOY_DIR / \".gitignore\").write_text(gitignore)\n",
        "print(\"✅ .gitignore saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dWMw_D4T8dA",
        "outputId": "16a9dd2f-0d65-4775-a1d8-7f59ba0dd5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ .gitignore saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readme = \"\"\"# UrbanSimAI Chicago (Public Demo)\n",
        "\n",
        "UrbanSimAI is a smart-city analytics demo for Chicago:\n",
        "- Predict hourly average traffic speed by ZIP (XGBoost)\n",
        "- Show map + 24-hour forecast\n",
        "- Uses open datasets (Chicago traffic, CTA GTFS, Zillow ZHVI)\n",
        "\n",
        "## Run locally\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "streamlit run streamlit_app.py\n",
        "```\n",
        "## Disclaimer\n",
        "\n",
        "Research/demo only. Not for safety-critical decisions.\n",
        "\"\"\"\n",
        "\n",
        "(DEPLOY_DIR / \"README.md\").write_text(readme)\n",
        "print(\"✅ README.md saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coCX-DoOUBde",
        "outputId": "76b521ea-a4f5-422b-cf10-60b2645ab3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ README.md saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = r'''\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import holidays\n",
        "import streamlit as st\n",
        "import pydeck as pdk\n",
        "\n",
        "st.set_page_config(page_title=\"UrbanSimAI Chicago\", layout=\"wide\")\n",
        "\n",
        "BASE = Path(__file__).parent\n",
        "DATA_DIR = BASE / \"data\"\n",
        "MODELS_DIR = BASE / \"models\"\n",
        "\n",
        "MODEL_PATH = MODELS_DIR / \"best_speed_model.pkl\"\n",
        "META_PATH  = MODELS_DIR / \"best_speed_model_meta.json\"\n",
        "\n",
        "TRAFFIC_ZIP_HOURLY = DATA_DIR / \"traffic_zip_hourly.parquet\"\n",
        "CTA_ZIP = DATA_DIR / \"cta_stops_by_zip.parquet\"\n",
        "ZILLOW_ZIP = DATA_DIR / \"zillow_zhvi_chicago_zip_long.parquet\"\n",
        "ZIP_GEOJSON = DATA_DIR / \"zip_boundaries.geojson\"\n",
        "\n",
        "US_HOL = holidays.US(state=\"IL\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = joblib.load(MODEL_PATH)\n",
        "    meta = json.loads(META_PATH.read_text())\n",
        "    return model, meta\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    traffic = pd.read_parquet(TRAFFIC_ZIP_HOURLY)\n",
        "    cta = pd.read_parquet(CTA_ZIP)\n",
        "    zillow = pd.read_parquet(ZILLOW_ZIP)\n",
        "\n",
        "    traffic[\"zip\"] = traffic[\"zip\"].astype(str).str.zfill(5)\n",
        "    cta[\"zip\"] = cta[\"zip\"].astype(str).str.zfill(5)\n",
        "    zillow[\"zip\"] = zillow[\"zip\"].astype(str).str.zfill(5)\n",
        "\n",
        "    traffic[\"hour_ts\"] = pd.to_datetime(traffic[\"hour_ts\"])\n",
        "    zillow[\"date\"] = pd.to_datetime(zillow[\"date\"])\n",
        "    return traffic, cta, zillow\n",
        "\n",
        "def time_features(ts: pd.Timestamp):\n",
        "    ts = pd.to_datetime(ts)\n",
        "    return {\n",
        "        \"hour\": int(ts.hour),\n",
        "        \"dow\": int(ts.dayofweek),\n",
        "        \"month\": int(ts.month),\n",
        "        \"weekofyear\": int(ts.isocalendar().week),\n",
        "        \"is_weekend\": int(ts.dayofweek >= 5),\n",
        "        \"is_holiday\": int(ts.date() in US_HOL),\n",
        "    }\n",
        "\n",
        "def get_static_features(zip_code, cta_df, zillow_df, ts):\n",
        "    row = cta_df[cta_df[\"zip\"] == zip_code]\n",
        "    cta_cnt = float(row[\"cta_stop_count\"].iloc[0]) if len(row) else 0.0\n",
        "\n",
        "    z = zillow_df[zillow_df[\"zip\"] == zip_code].sort_values(\"date\")\n",
        "    if len(z) == 0:\n",
        "        zhvi = float(zillow_df[\"zhvi\"].median())\n",
        "    else:\n",
        "        z2 = z[z[\"date\"] <= ts]\n",
        "        zhvi = float(z2[\"zhvi\"].iloc[-1]) if len(z2) else float(z[\"zhvi\"].iloc[0])\n",
        "    return cta_cnt, zhvi\n",
        "\n",
        "def build_feature_row(zip_code, ts, hist_df, cta_df, zillow_df):\n",
        "    h = hist_df.sort_values(\"hour_ts\").copy()\n",
        "\n",
        "    def lag(hours_back):\n",
        "        target = ts - timedelta(hours=hours_back)\n",
        "        m = h[h[\"hour_ts\"] == target]\n",
        "        return float(m[\"avg_speed\"].iloc[0]) if len(m) else np.nan\n",
        "\n",
        "    prev24 = h[h[\"hour_ts\"] < ts].tail(24)[\"avg_speed\"].astype(float).to_numpy()\n",
        "\n",
        "    cta_cnt, zhvi = get_static_features(zip_code, cta_df, zillow_df, ts)\n",
        "    tf = time_features(ts)\n",
        "\n",
        "    row = {\n",
        "        \"zip\": zip_code,\n",
        "        \"cta_stop_count\": cta_cnt,\n",
        "        \"zhvi\": zhvi,\n",
        "        **tf,\n",
        "        \"lag_1\": lag(1),\n",
        "        \"lag_2\": lag(2),\n",
        "        \"lag_3\": lag(3),\n",
        "        \"lag_24\": lag(24),\n",
        "        \"lag_168\": lag(168),\n",
        "        \"roll_mean_3\": float(np.mean(prev24[-3:])) if len(prev24) >= 3 else np.nan,\n",
        "        \"roll_mean_6\": float(np.mean(prev24[-6:])) if len(prev24) >= 6 else np.nan,\n",
        "        \"roll_mean_24\": float(np.mean(prev24)) if len(prev24) >= 2 else np.nan,\n",
        "        \"roll_std_24\": float(np.std(prev24)) if len(prev24) >= 2 else np.nan,\n",
        "    }\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "def align_onehot(X, model):\n",
        "    X = pd.get_dummies(X, columns=[\"zip\"], drop_first=False)\n",
        "    if hasattr(model, \"feature_names_in_\"):\n",
        "        return X.reindex(columns=list(model.feature_names_in_), fill_value=0)\n",
        "    return X\n",
        "\n",
        "def forecast_next_24(zip_code, traffic_df, cta_df, zillow_df, model):\n",
        "    h = traffic_df[traffic_df[\"zip\"] == zip_code][[\"hour_ts\", \"avg_speed\"]].copy()\n",
        "    h = h.sort_values(\"hour_ts\").tail(2000).copy()\n",
        "\n",
        "    last_ts = h[\"hour_ts\"].max()\n",
        "    preds = []\n",
        "    cur = h.copy()\n",
        "\n",
        "    for step in range(1, 25):\n",
        "        ts = last_ts + timedelta(hours=step)\n",
        "        X = build_feature_row(zip_code, ts, cur, cta_df, zillow_df)\n",
        "        if X.isna().any().any():\n",
        "            break\n",
        "        Xa = align_onehot(X, model)\n",
        "        yhat = float(model.predict(Xa)[0])\n",
        "        preds.append({\"hour_ts\": ts, \"pred_speed\": yhat})\n",
        "        cur = pd.concat([cur, pd.DataFrame([{\"hour_ts\": ts, \"avg_speed\": yhat}])], ignore_index=True)\n",
        "\n",
        "    return pd.DataFrame(preds)\n",
        "\n",
        "def load_geojson():\n",
        "    import json as _json\n",
        "    return _json.loads(ZIP_GEOJSON.read_text())\n",
        "\n",
        "def build_map(geojson, value_by_zip):\n",
        "    feats = geojson[\"features\"]\n",
        "    vals = []\n",
        "    for f in feats:\n",
        "        z = str(f[\"properties\"].get(\"zip\", \"\")).zfill(5)\n",
        "        v = value_by_zip.get(z, None)\n",
        "        f[\"properties\"][\"speed\"] = None if v is None else float(v)\n",
        "        if v is not None:\n",
        "            vals.append(float(v))\n",
        "\n",
        "    vmin = float(np.min(vals)) if vals else 0.0\n",
        "    vmax = float(np.max(vals)) if vals else 1.0\n",
        "    if vmax == vmin:\n",
        "        vmax = vmin + 1.0\n",
        "\n",
        "    layer = pdk.Layer(\n",
        "        \"GeoJsonLayer\",\n",
        "        geojson,\n",
        "        stroked=True,\n",
        "        filled=True,\n",
        "        opacity=0.65,\n",
        "        get_line_color=[60, 60, 60],\n",
        "        get_fill_color=f\"[255*(speed-{vmin})/({vmax}-{vmin}), 120, 255*(1-(speed-{vmin})/({vmax}-{vmin}))]\",\n",
        "        pickable=True,\n",
        "    )\n",
        "    view = pdk.ViewState(latitude=41.8781, longitude=-87.6298, zoom=9)\n",
        "    return pdk.Deck(layers=[layer], initial_view_state=view, tooltip={\"text\": \"ZIP: {zip}\\nSpeed: {speed} mph\"})\n",
        "\n",
        "# ---------------- UI ----------------\n",
        "st.title(\"UrbanSimAI Chicago — Traffic Speed Forecasting\")\n",
        "st.caption(\"XGBoost model + open data. Forecast next 24 hours by ZIP + map view.\")\n",
        "\n",
        "model, meta = load_model()\n",
        "traffic_df, cta_df, zillow_df = load_data()\n",
        "\n",
        "zip_list = sorted(traffic_df[\"zip\"].unique().tolist())\n",
        "\n",
        "c1, c2, c3 = st.columns([1, 1, 2])\n",
        "with c1:\n",
        "    zip_code = st.selectbox(\"Select ZIP\", zip_list, index=0)\n",
        "with c2:\n",
        "    mode = st.radio(\"Mode\", [\"Forecast next 24 hours\", \"Backtest (pick an hour)\"])\n",
        "with c3:\n",
        "    st.write(\"**Best model:**\", meta.get(\"best_model\", \"XGBoost\"))\n",
        "    st.write(\"**Test MAE:**\", round(meta.get(\"final_test_mae\", 0.0), 3),\n",
        "             \"| **RMSE:**\", round(meta.get(\"final_test_rmse\", 0.0), 3))\n",
        "\n",
        "if mode == \"Backtest (pick an hour)\":\n",
        "    sub = traffic_df[traffic_df[\"zip\"] == zip_code].sort_values(\"hour_ts\")\n",
        "    ts = st.selectbox(\"Pick an hour\", sub[\"hour_ts\"].tail(500).tolist())\n",
        "    X = build_feature_row(zip_code, pd.to_datetime(ts), sub[[\"hour_ts\",\"avg_speed\"]], cta_df, zillow_df)\n",
        "\n",
        "    if X.isna().any().any():\n",
        "        st.warning(\"Not enough history for lag features here. Pick a later hour.\")\n",
        "    else:\n",
        "        pred = float(model.predict(align_onehot(X, model))[0])\n",
        "        actual = float(sub[sub[\"hour_ts\"] == pd.to_datetime(ts)][\"avg_speed\"].iloc[0])\n",
        "        st.metric(\"Predicted speed (mph)\", round(pred, 2))\n",
        "        st.metric(\"Actual speed (mph)\", round(actual, 2))\n",
        "        st.dataframe(X)\n",
        "else:\n",
        "    pred_df = forecast_next_24(zip_code, traffic_df, cta_df, zillow_df, model)\n",
        "    if len(pred_df) == 0:\n",
        "        st.warning(\"Not enough history to forecast. Try another ZIP.\")\n",
        "    else:\n",
        "        st.subheader(f\"Next 24 hours forecast — ZIP {zip_code}\")\n",
        "        st.dataframe(pred_df)\n",
        "        st.line_chart(pred_df.set_index(\"hour_ts\")[\"pred_speed\"])\n",
        "\n",
        "st.divider()\n",
        "st.subheader(\"Map: Latest observed hourly avg speed by ZIP\")\n",
        "last_hour = traffic_df[\"hour_ts\"].max()\n",
        "snap = traffic_df[traffic_df[\"hour_ts\"] == last_hour][[\"zip\", \"avg_speed\"]].copy()\n",
        "value_by_zip = dict(zip(snap[\"zip\"], snap[\"avg_speed\"]))\n",
        "\n",
        "geojson = load_geojson()\n",
        "deck = build_map(geojson, value_by_zip)\n",
        "st.pydeck_chart(deck)\n",
        "st.caption(f\"Latest hour in dataset: {last_hour}\")\n",
        "\n",
        "st.divider()\n",
        "st.caption(\"Disclaimer: research/demo only. Do not use for safety-critical decisions.\")\n",
        "'''\n",
        "(DEPLOY_DIR / \"streamlit_app.py\").write_text(app)\n",
        "print(\"✅ streamlit_app.py saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6biltk0Pw8l",
        "outputId": "ea035b4c-fb6c-4ed9-8a23-55151adcfc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ streamlit_app.py saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- DEPLOY FILE LIST ----\")\n",
        "for p in sorted(DEPLOY_DIR.rglob(\"*\")):\n",
        "    if p.is_file():\n",
        "        print(p.relative_to(DEPLOY_DIR), \"|\", round(p.stat().st_size/1e6, 2), \"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzIfNAsxP8F6",
        "outputId": "be43253d-d1a1-41e6-d2a8-41d5164bb76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- DEPLOY FILE LIST ----\n",
            ".gitignore | 0.0 MB\n",
            "README.md | 0.0 MB\n",
            "data/cta_stops_by_zip.parquet | 0.0 MB\n",
            "data/traffic_zip_hourly.parquet | 0.76 MB\n",
            "data/zillow_zhvi_chicago_zip_long.parquet | 0.18 MB\n",
            "data/zip_boundaries.geojson | 1.64 MB\n",
            "models/best_speed_model.pkl | 20.98 MB\n",
            "models/best_speed_model_meta.json | 0.0 MB\n",
            "requirements.txt | 0.0 MB\n",
            "streamlit_app.py | 0.01 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#END"
      ],
      "metadata": {
        "id": "7YtPNdvsQCqG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}